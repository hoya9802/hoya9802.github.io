---
layout: single
title:  "Paper Review - FCN(Fully Convolutional Networks for Semantic Segmentation)"
typora-root-url: ../
categories: Paper-Review
tag: [CNN, semantic segmentation, FCN]
author_profile: false
sidebar:
    nav: 'counts'
search: true
use_math: true
redirect_from:
  - /paper/FCN
published: false
---

**[Reference]** [CVPR2015 FCN Paper](https://arxiv.org/pdf/1411.4038.pdf){:target="_blank"}
{: .notice}

## Abstract
해당 논문은 key insight는 임의의 크기의 입력을 받아들이고 효율적인 추론과 학습을 통해 해당 크기의 출력을 생성하는 "fully convolutional" 네트워크를 구축하는 것입니다. 또한 AlexNet, VGG16, GoogLeNet과 같은 현대적인 networks를 수용하여 fully convolutional network를 구성했으며, 사전 학습된 representations를 변환하여 segmentation task에 적용하였습니다. 

해당 논문은 deep, coarse layer에서 semantic 정보와 shallow, fine layer에서의 appearance 정보를 결합한 skip architecture를 정의하였습니다. 그 결과 SOTA(state-of-art) segmentation를 달성하였습니다.<br>
(fine이 섬세함을 뜻하고, coarse는 fine의 반대말로 rough하면서 non-smooth함을 나타낸다. 쉽게 설명하면 fine은 섬세하게 보는 것이고, coarse는 섬세하지 않지만 전반적으로 보는 것을 의미한다.)

## 1. Introduction
<br>
![figure1](/images/2023-11-16-FCN/figure1.png){: .img-width-half .align-center}

Convolution network는 물체 인식에서 발전을 주도하고 있으며, Convnet는 whole-image에 대한 classification를 향상시킬 뿐만 아니라 structured ouput의 local task에서도 전진을 이루고 있습니다.
(structured output는 output 자체가 단순하게 하나의 label, class로만 갖는 것이 아니라 각각의 pixel들이 이미지 속 특정 객체의 영역을 가져 구조화 되는 것을 의미합니다.)

논문에서는 <span style="color:red">추가적인 기계학습적 요소없이 end-to-end로 모델을 학습하고 semantic segmentation에서 SOTA(state-of-the-art)를 뛰어 넘었습니다.</span> 그리고 (1) pixelwise prediction과 supervised pre-training를 위한 end-to-end로 모델을 학습하는 것을 처음 시도하였습니다. 존재하는 여러 network들의 fully convolutional version들은 임의의 input 사이즈에 대해서 학습을 가능하게 합니다.

이전 연구들과 다르게 이미지 전처리, 후처리 과정이 필요하지 않습니다. 모델은 최근 성공한 모델들에서 그들의 learned representations을 가져와 fully convolutional, fine-tuning를 하고, 이러한 classification network를 재해석하여 Dense prediction할 수 있도록 변환하였습니다 (see Figure <span style='color:red'>1</span>).

## 2. Related work
논문에서는 semantic segmentation의 direct, dense prediction를 위해 기존 VGG, LeNet, AlexNet의 구조를 재구성하였습니다.

 - Mantan et al. : 임의의 input size에 대한 convnet을 확장하는 아이디어가 처음 등장
 - Wolf and Platt : CNN의 출력을 가져와 해당 출력을 사용하여 postal address block에 대한 감지 점수를 나타내는 2차원 맵을 생성
 - Ning et al. : C.elegans(선충중 하나로 간단한 형태를 가진 다세포 생물) 조직의 대략적인 multiclass segmentation를 위한 Convnet을 Fully convolutional 추론으로 정의합니다.

Fully convolutional 연산은 많은 layer를 가지는 현대시대의 네트워크에도 많이 활동되었습니다.
 
 - Sermanet : Sliding window detection
 - Pinheiro and Collobert : Semantic segmentation
 - Eigen et al. : image restoration
 - Tompson et al. : End-to-end로 part detector, pose estimation을 위한 공간적 모델로서 학습시키기 위해 fully convolutional training을 드물게나마 효과적으로 활용했다.
 - He et al. : feature 추출을 위해 classification nets의 non-convolutional 요소들을 제거하였다.

각각의 자세한 방법들은 각각의 논문들을 참조하세요.

몇몇의 최신 연구들은 convnet들을 dense prediction problems들의 적용하였다. 그리고 아래의 요소들을 포함시켰습니다.

 - small models restricting capacity and receptive fields;
 - patchwise tranining;
 - post-processing(superpixel projection, random field regularization, filtering, etc.)
 - input shifting and output interlacing for dense output;
 - multi-scale pyramid processing;
 - saturating tanh nonlinearities;
 - ensembles;

위에서 언급한 <span style="color:red">**machinery**들이 없이도</span> supervised pre-training과 fully convolutionally을 fine-tune함으로써 image classification을 사용하고 이런 deep classification nets을 확장함으로서 <span style="color:red">**whole image inputs과 whole image ground thruths**을 보다 더 쉽고 효율적으로 학습할 수 있었습니다.</span>

## 3. Fully convolutional networks
Convnet의 convolution, pooling, activation function들 덕분에 translation invariance 성질을 가지게 됩니다.


위에 그림을 보면 $y_{ij}$ 값이 basic component들의 의해 작아졌지만 기존 $x_{ij}$의 상대적인 공간 좌표를 가지고 있는 것을 확인 할 수 있습니다.
 
독립적으로 patch-by-patch로 연산하는 것보다 전체 이미지에 대해서 layer-by-layer로 학습을 하는 것이 feedforward, backpropagation에서 훨씯 더 효율적입니다.

Pixelwise prediction을 수행하기 위해서는 coarse한 출력을 다시 픽셀들에 연결해 주어야 합니다.

### 3.1. Adapting classifiers for dense prediction
<br>
![figure2](/images/2023-11-16-FCN/figure2.png){: .img-width-half .align-center}

기존 recognition net들은 표면적으로는 고정된 input과 non-spatial한 output를 생성합니다. 이러한 net들의 fully connected layer들은 고정된 dimension들을 가지고 spatial coordinate들을 제거한다. 하지만 이런 fully connected layer들은 convolution으로서 kernel들과 함께 전체 이미지의 지역들을 커버하여 classification을 해준다. 따라서 이 네트워크들을 <span style='color:red'>**fully convolutional network로 변환함**</span>으로서 아무런 사이즈의 input를 받아올 수 있고, output으로 classification map을 가져올 수 있다(see Figure <span style='color:red'>2</span>).

Fully convolutional net으로 만들어진 모델의 spatial output map들은 자연스럽게 semantic segmentation과 같은 dense problem들을 하게끔 선택된다. 모든 output cell에 대한 ground truth가 가능해짐에 따라 기존 방식처럼 전처리, 후처리, any machinery들이 필요 없기 때문에 forward와 backward pass들이 더 수월해진다.

## 3.2. Shift-and-stitch is filter rarefaction

