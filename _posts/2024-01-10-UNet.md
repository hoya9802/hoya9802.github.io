---
layout: single
title:  "Paper Review - UNet"
typora-root-url: ../
categories: Paper-Review
tag: [CNN, semantic segmentation, UNet]
author_profile: false
sidebar:
    nav: 'counts'
search: true
use_math: true
redirect_from:
  - /paper/UNet
published: false
---

**[Reference]** [UNet Paper](https://arxiv.org/pdf/1505.04597.pdf){:target="_blank"}
{: .notice}

## Abstract.
The U-Net, proposed in 2015, represents a CNN framework primarity employed for image segmentation tasks. this model was designed for medical image segmentation.

It comprises <span style='color:red'>**two main features**</span>:
 - <span style='color:red'>Contracting path:</span> Responsible for feature extraction of context(Overall image with information such as texture, color, shape, etc. around a pixel or object)
 - <span style='color:red'>Symmetric expanding path:</span> Facilitating precise localization

Due to these features, U-Net demonstrates remarkable performance in segmentation tasks and outperforms the prior best method(<span style='color:yellow'>a sliding-window convolutional network</span>)

* <span style='color:yellow'>Sliding-window convolutional network<br>
<br>
![sliding_window_example](/images/2024-01-10-UNet/sliding_window_example.gif)
{: .img-width-half .align-center}
<span style='color:yellow'>In order to find multi objects in a large image, divide the entire image into areas of the right and apply the localization network made in the previous step repeating for each area.</span>

U-Net is so fast because inference time of segmentation of a 512x512 image takes less than a second on a recent GPU. Just looking at it, the existing method sliding-window convolutional network seems to take a long time to infer.

## 1, Introduction
![u-net-architecture](/images/2024-01-10-UNet/UNet-arc.png){: .align-center}<br>
This model was built upon by [FCN](https://hoya9802.github.io/paper-review/FCN/)<span style='color:yellow'>(you can check the organized FCN in that link)</span>. In this paper, they tried to modify and extent this model such that it works with very few training datasets and yields more precise result (see Figure <span style='color:red'>1</span>).

One significant modification in this architecture is the inclusion of a large number of feature channels in the upsampling part. This enhancement enables the network to convey context information to higher-resolution layers. <span style='color:red'>Consequently, the expansive path(=Decoding path) is approximately symmetric to the contracting path(=Encoding path), resulting in a ***U-shaped architecture***.</span>

### Overlap-tile strategy
![overlap-tile](/images/2024-01-10-UNet/overlap-tile.png){: .align-center}<br>
The blue box in above image (left) represents the input image to the network. Due to the use of valid convolutions (without any padding), the output is supposed to be the smaller yellow box (right).

They're illustrating that <span style='color:yellow'>the image they want to predict on is larger than the input to the network, possibly due to limited GPU memory.</span> Hence, they need to perform inference multiple times using different parts of the input.

On the right side, imagine shifting the yellow box downward so that it aligns with the original square. Repeat this process to "tile" the output space. This requires a larger region of the input (blue) for inference. For non-overlapping yellow boxes in the output, overlapping blue boxes are needed for the input.


### Mirroring extrapolation strategy
![mirror_padding](/images/2024-01-10-UNet/mirror_padding.jpeg){: .img-width-half .align-center}<br>
As you can see from the red arrow, it is a method of padding the empty space of the boundary by symmetrical existing images.

This strategy to improve predicion result about border regions of an imput image.

### Elastic deformation
![elastic_deformation](/images/2024-01-10-UNet/elastic_deformation.png)<br>


Elastic deformation is a technique used to augment training data by applying random distortions to images, helping AI models learn to recognize objects under different conditions (see above image).

This enables the network to learn invariant to such deformations, eliminating the necessity to encounter these transformations in the annotated image corpus. This practice is crucial in biomedical segmentation, where tissue deformation is a common variation, and realistic deformations can be efficiently simulated.

